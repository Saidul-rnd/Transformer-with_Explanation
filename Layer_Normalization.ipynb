{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i6uQdVeuJHB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.Tensor([[[0.2,0.1,0.3], [0.5, 0.1,0.1]]])\n",
        "\"\"\" Here we added batches, as we want to normalize not only the last\n",
        "layer(embedding), also by batches. SO Layer normalization is going to be\n",
        "computed across layer and also the batch.\n",
        "thats why here we reshape our input, and bring the batch as 2nd last that\n",
        "that we can process embedding and batch along with together\"\"\"\n",
        "B, S, E = inputs.size()\n",
        "inputs = inputs.reshape(S, B, E)\n",
        "inputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9X2U4U5z7uW",
        "outputId": "85ef6b4b-1ce5-403d-b174-6581347f971f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_shape = inputs.size()[-2:] # for parameter, we are considering only last 2,as the norm will apply embedding and batch\n",
        "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
        "beta = nn.Parameter(torch.zeros(parameter_shape))"
      ],
      "metadata": {
        "id": "D5wF__9K0SLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" the reason here, we can see only the last two dimention here,\n",
        "becuase again!the layer norm will be applied on batch and embedding\"\"\"\n",
        "gamma.size(), beta.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJedGR8L0kfb",
        "outputId": "6b492075-aa84-47a2-b966-9f629f9d8774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([1, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculating the dimentions of the batch and embedding dimentionss, as the layer norm will be applied here.\n",
        "dims = [-(i + 1) for i in range(len(parameter_shape))] ##comprehension :python\n",
        "dims # so it shows the last two dimentions where the layer norm will be applied."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRsrseLn0pZY",
        "outputId": "be1880f0-7c80-45ab-f94d-3b7bd101baa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1, -2]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" So for normalization, we will calculate the mean across layer and batch\"\"\"\n",
        "mean = inputs.mean(dim = dims, keepdim = True)\n",
        "mean.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvVGU40j3opu",
        "outputId": "59fadfde-a63d-4553-b003-bbecdde99c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGjl7ZFS4Jiu",
        "outputId": "2e9ab9ff-f914-451e-fa08-a98c1aa019cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2000]],\n",
              "\n",
              "        [[0.2333]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" we need STD as well, lets calculate standard daviation-STD for normalization \"\"\"\n",
        "var = ((inputs - mean) ** 2).mean (dim=dims, keepdim = True)\n",
        "epsilon = 1e-5 ## are adding epsilone during STD calculation, as STD will be denominator, so that it does not become zero.\n",
        "std = (var +epsilon).sqrt()\n",
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OBuiQt94LVi",
        "outputId": "ac0b8f7c-7a27-4c08-f0b5-339998fac00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0817]],\n",
              "\n",
              "        [[0.1886]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Apply normalization formula \"\"\"\n",
        "y = (inputs - mean)/ std\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHQ9719341Ao",
        "outputId": "a8f91eff-6f7f-4ebf-de32-2937d2654c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## the final output of layer normalization\n",
        "out = gamma * y + beta\n",
        "out ## here in the tensor we can see, grad_fn parameter, this parameter is not gamma & beta, which is learnable."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opavbDH248ez",
        "outputId": "902a14c0-0394-46ef-f547-00946111879f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a class for what we have done so far"
      ],
      "metadata": {
        "id": "d5egbyHm50vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LayerNormalization():\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, input):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
        "        out = self.gamma * y  + self.beta\n",
        "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
        "        return out"
      ],
      "metadata": {
        "id": "_77ObEpt5sfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the layer normalization using the layer norm class"
      ],
      "metadata": {
        "id": "J2ApsddK55k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8\n",
        "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
        "\n",
        "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvq1XX-e53hE",
        "outputId": "2eaed64b-15f8-43da-a217-685a41afbf18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-0.2364, -0.6338, -0.8136,  1.1681,  1.2041, -1.2963,  1.3588,\n",
            "          -0.2183],\n",
            "         [ 0.9932,  0.5894, -1.1784, -0.5347, -0.3060,  0.3411,  1.5260,\n",
            "           1.6832],\n",
            "         [ 0.9735, -1.2352,  0.3909, -0.8722,  0.6739, -2.6895,  0.1192,\n",
            "          -0.5708]],\n",
            "\n",
            "        [[ 1.6261, -0.7122,  0.0905,  0.7380,  0.2301,  1.1817, -1.2036,\n",
            "           1.0570],\n",
            "         [ 0.6507,  0.2438, -0.2595,  1.5971,  1.4274,  0.4059, -0.3605,\n",
            "           0.7279],\n",
            "         [ 0.2835,  1.8822, -0.2638, -0.9029,  0.2947,  0.7813,  2.1086,\n",
            "          -0.1727]],\n",
            "\n",
            "        [[ 1.4508,  0.4152,  0.0220, -0.7879,  1.3054, -0.1078,  0.3189,\n",
            "           0.6838],\n",
            "         [-1.4393,  0.0056, -1.1333,  0.9543,  2.0164,  1.4971, -0.9736,\n",
            "          -0.8344],\n",
            "         [ 0.2225, -0.1916,  0.1652,  1.5632, -0.9313, -0.2051, -0.7447,\n",
            "           0.4788]],\n",
            "\n",
            "        [[ 0.5901,  1.6292,  0.2596,  0.1191,  1.0151,  0.8403,  1.2528,\n",
            "          -0.5778],\n",
            "         [-2.0575,  0.2575,  2.0777, -0.0768,  0.8691, -0.0076, -0.9034,\n",
            "           0.6454],\n",
            "         [-0.3556,  0.6871, -1.1467, -0.1880, -0.2012, -0.1290, -1.3067,\n",
            "          -2.7392]],\n",
            "\n",
            "        [[ 0.4194,  0.0328,  0.2554,  0.5224, -0.5025, -0.6299,  0.5851,\n",
            "          -0.7773],\n",
            "         [ 0.8703, -0.2180,  1.1629, -0.4212,  1.0021,  1.0894,  0.4965,\n",
            "          -0.5745],\n",
            "         [-0.3665,  1.8540,  0.3481,  1.4052, -0.5123,  0.3572, -0.9904,\n",
            "           1.0697]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_norm = LayerNormalization(inputs.size()[-1:])"
      ],
      "metadata": {
        "id": "FWOS7kBC5-3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = layer_norm.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tZGqZWx6ApD",
        "outputId": "2390f8ab-235d-475f-c73e-441b99d38235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[ 0.0666],\n",
            "         [ 0.3892],\n",
            "         [-0.4013]],\n",
            "\n",
            "        [[ 0.3760],\n",
            "         [ 0.5541],\n",
            "         [ 0.5014]],\n",
            "\n",
            "        [[ 0.4125],\n",
            "         [ 0.0116],\n",
            "         [ 0.0446]],\n",
            "\n",
            "        [[ 0.6410],\n",
            "         [ 0.1005],\n",
            "         [-0.6724]],\n",
            "\n",
            "        [[-0.0118],\n",
            "         [ 0.4259],\n",
            "         [ 0.3956]]])\n",
            "Standard Deviation \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[0.9665],\n",
            "         [0.9466],\n",
            "         [1.1251]],\n",
            "\n",
            "        [[0.9075],\n",
            "         [0.6621],\n",
            "         [0.9792]],\n",
            "\n",
            "        [[0.6912],\n",
            "         [1.2358],\n",
            "         [0.7275]],\n",
            "\n",
            "        [[0.6554],\n",
            "         [1.1473],\n",
            "         [0.9747]],\n",
            "\n",
            "        [[0.5136],\n",
            "         [0.6755],\n",
            "         [0.9308]]])\n",
            "y \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-0.3135, -0.7247, -0.9107,  1.1397,  1.1769, -1.4101,  1.3371,\n",
            "          -0.2947],\n",
            "         [ 0.6380,  0.2115, -1.6561, -0.9761, -0.7345, -0.0508,  1.2009,\n",
            "           1.3670],\n",
            "         [ 1.2219, -0.7413,  0.7041, -0.4185,  0.9556, -2.0338,  0.4627,\n",
            "          -0.1507]],\n",
            "\n",
            "        [[ 1.3775, -1.1990, -0.3145,  0.3989, -0.1607,  0.8879, -1.7405,\n",
            "           0.7504],\n",
            "         [ 0.1460, -0.4686, -1.2289,  1.5753,  1.3191, -0.2239, -1.3813,\n",
            "           0.2625],\n",
            "         [-0.2225,  1.4102, -0.7814, -1.4341, -0.2111,  0.2859,  1.6415,\n",
            "          -0.6884]],\n",
            "\n",
            "        [[ 1.5021,  0.0038, -0.5650, -1.7368,  1.2918, -0.7529, -0.1355,\n",
            "           0.3925],\n",
            "         [-1.1741, -0.0048, -0.9265,  0.7628,  1.6223,  1.2021, -0.7972,\n",
            "          -0.6846],\n",
            "         [ 0.2445, -0.3247,  0.1657,  2.0873, -1.3414, -0.3433, -1.0849,\n",
            "           0.5968]],\n",
            "\n",
            "        [[-0.0778,  1.5077, -0.5821, -0.7963,  0.5707,  0.3040,  0.9334,\n",
            "          -1.8596],\n",
            "         [-1.8810,  0.1368,  1.7234, -0.1546,  0.6699, -0.0943, -0.8751,\n",
            "           0.4749],\n",
            "         [ 0.3251,  1.3949, -0.4866,  0.4970,  0.4834,  0.5575, -0.6508,\n",
            "          -2.1205]],\n",
            "\n",
            "        [[ 0.8397,  0.0869,  0.5204,  1.0403, -0.9554, -1.2036,  1.1623,\n",
            "          -1.4905],\n",
            "         [ 0.6578, -0.9532,  1.0910, -1.2540,  0.8529,  0.9821,  0.1045,\n",
            "          -1.4809],\n",
            "         [-0.8188,  1.5669, -0.0511,  1.0847, -0.9755, -0.0413, -1.4891,\n",
            "           0.7242]]])\n",
            "out \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-0.3135, -0.7247, -0.9107,  1.1397,  1.1769, -1.4101,  1.3371,\n",
            "          -0.2947],\n",
            "         [ 0.6380,  0.2115, -1.6561, -0.9761, -0.7345, -0.0508,  1.2009,\n",
            "           1.3670],\n",
            "         [ 1.2219, -0.7413,  0.7041, -0.4185,  0.9556, -2.0338,  0.4627,\n",
            "          -0.1507]],\n",
            "\n",
            "        [[ 1.3775, -1.1990, -0.3145,  0.3989, -0.1607,  0.8879, -1.7405,\n",
            "           0.7504],\n",
            "         [ 0.1460, -0.4686, -1.2289,  1.5753,  1.3191, -0.2239, -1.3813,\n",
            "           0.2625],\n",
            "         [-0.2225,  1.4102, -0.7814, -1.4341, -0.2111,  0.2859,  1.6415,\n",
            "          -0.6884]],\n",
            "\n",
            "        [[ 1.5021,  0.0038, -0.5650, -1.7368,  1.2918, -0.7529, -0.1355,\n",
            "           0.3925],\n",
            "         [-1.1741, -0.0048, -0.9265,  0.7628,  1.6223,  1.2021, -0.7972,\n",
            "          -0.6846],\n",
            "         [ 0.2445, -0.3247,  0.1657,  2.0873, -1.3414, -0.3433, -1.0849,\n",
            "           0.5968]],\n",
            "\n",
            "        [[-0.0778,  1.5077, -0.5821, -0.7963,  0.5707,  0.3040,  0.9334,\n",
            "          -1.8596],\n",
            "         [-1.8810,  0.1368,  1.7234, -0.1546,  0.6699, -0.0943, -0.8751,\n",
            "           0.4749],\n",
            "         [ 0.3251,  1.3949, -0.4866,  0.4970,  0.4834,  0.5575, -0.6508,\n",
            "          -2.1205]],\n",
            "\n",
            "        [[ 0.8397,  0.0869,  0.5204,  1.0403, -0.9554, -1.2036,  1.1623,\n",
            "          -1.4905],\n",
            "         [ 0.6578, -0.9532,  1.0910, -1.2540,  0.8529,  0.9821,  0.1045,\n",
            "          -1.4809],\n",
            "         [-0.8188,  1.5669, -0.0511,  1.0847, -0.9755, -0.0413, -1.4891,\n",
            "           0.7242]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0].mean(), out[0].std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpcs-w7n6CYe",
        "outputId": "11a8066b-0032-4911-8c87-e1a818f27065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.9802e-08, grad_fn=<MeanBackward0>),\n",
              " tensor(1.0215, grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}